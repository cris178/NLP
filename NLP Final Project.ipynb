{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cristian Reyes\n",
    "\n",
    "# Text Summarizer\n",
    "This project is for Natural Language Processing at UCR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "First we will need to take our source of text and turn it into sentences. We will need a web crawler and a way to find the content in the web filer which are of form xml html. In order to find the text we go into the body tag and find the p tags in the html which have all the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pip install beautifulsoup4\n",
    "## Web Crawler\n",
    "\n",
    "##pip install lxml\n",
    "##Crawl xml html\n",
    "\n",
    "#import web crawl libraries beautiful soup\n",
    "import bs4 as bs  \n",
    "import urllib.request  \n",
    "import re\n",
    "\n",
    "scraped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence')  \n",
    "article = scraped_data.read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:  \n",
    "    article_text += p.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Now that we have the text in a list of paragraphs we start pre processing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets remove the refrences in the wikipedia articles which appear as square brackets and the extra space left behind\n",
    "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)  \n",
    "article_text = re.sub(r'\\s+', ' ', article_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new object in order to keep original article intact\n",
    "# Remove special characters and digits\n",
    "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )  \n",
    "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
